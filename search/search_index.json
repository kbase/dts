{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Overview The Data Transfer Service (DTS) is a web service that handles requests for file transfers between participating organizations interested in exchanging biological and bioinformatical data. The DTS coordinates provides a single point of access for these organizations, allowing an end user or another service to search for datasets / files within any participating organization based on criteria specified in an ElasticSearch style query select any or all files from a search and request a transfer from the source organization to another participating organization DTS is designed for easy deployment and maintenance behind a gateway that provides TLS/SSL encryption. Requests to the DTS include headers with authentication information, so these requests rely on the HTTPS protocol to protect this information. It's very easy to deploy DTS in a Docker environment and configure it using environment variables.","title":"Home"},{"location":"index.html#overview","text":"The Data Transfer Service (DTS) is a web service that handles requests for file transfers between participating organizations interested in exchanging biological and bioinformatical data. The DTS coordinates provides a single point of access for these organizations, allowing an end user or another service to search for datasets / files within any participating organization based on criteria specified in an ElasticSearch style query select any or all files from a search and request a transfer from the source organization to another participating organization DTS is designed for easy deployment and maintenance behind a gateway that provides TLS/SSL encryption. Requests to the DTS include headers with authentication information, so these requests rely on the HTTPS protocol to protect this information. It's very easy to deploy DTS in a Docker environment and configure it using environment variables.","title":"Overview"},{"location":"admin/index.html","text":"DTS Administrator Guide Installing DTS Locally Deploying DTS via Docker Configuring DTS Granting DTS Access to a Globus Endpoint More soon!","title":"Overview"},{"location":"admin/index.html#dts-administrator-guide","text":"Installing DTS Locally Deploying DTS via Docker Configuring DTS Granting DTS Access to a Globus Endpoint More soon!","title":"DTS Administrator Guide"},{"location":"admin/config.html","text":"Configuring DTS You can configure a DTS instance by creating a YAML text file similar to dts.yaml.example in the repository. Typically this file is named dts.yaml , and is passed as an argument to the dts executable. Here we describe the different sections in this file and how they affect your DTS instance. Configuration File Sections Click on any of the links below to see the relevant details for a section. service : configure\u0455 settings for the DTS web service such as the port on which it listens, the maximum number of connections, intervals for polling and scrubbing completed tasks, data directories, and diagnostics endpoints : configures the endpoints used to transfer files from one place to another databases : configures databases for organizations that integrate with the DTS Each of these sections is described below, with a motivating example. service service : port : 8080 max_connections : 100 poll_interval : 60000 endpoint : globus-local data_dir : /path/to/dir delete_after : 604800 debug : true TODO: write some stuff! endpoints endpoints : globus-local : name : name-of-local-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> globus-jdp : name : name-of-jdp-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> globus-kbase : name : name-of-kbase-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> TODO: Things and stuff databases databases : jdp : name : JGI Data Portal organization : Joint Genome Institute endpoint : globus-jdp kbase : name : KBase Workspace Service (KSS) organization : KBase endpoint : globus-kbase TODO: Alll the things","title":"Configuring DTS"},{"location":"admin/config.html#configuring-dts","text":"You can configure a DTS instance by creating a YAML text file similar to dts.yaml.example in the repository. Typically this file is named dts.yaml , and is passed as an argument to the dts executable. Here we describe the different sections in this file and how they affect your DTS instance.","title":"Configuring DTS"},{"location":"admin/config.html#configuration-file-sections","text":"Click on any of the links below to see the relevant details for a section. service : configure\u0455 settings for the DTS web service such as the port on which it listens, the maximum number of connections, intervals for polling and scrubbing completed tasks, data directories, and diagnostics endpoints : configures the endpoints used to transfer files from one place to another databases : configures databases for organizations that integrate with the DTS Each of these sections is described below, with a motivating example.","title":"Configuration File Sections"},{"location":"admin/config.html#service","text":"service : port : 8080 max_connections : 100 poll_interval : 60000 endpoint : globus-local data_dir : /path/to/dir delete_after : 604800 debug : true TODO: write some stuff!","title":"service"},{"location":"admin/config.html#endpoints","text":"endpoints : globus-local : name : name-of-local-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> globus-jdp : name : name-of-jdp-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> globus-kbase : name : name-of-kbase-endpoint id : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx provider : globus auth : client_id : <ID of client with authentication secret> client_secret : <secret> TODO: Things and stuff","title":"endpoints"},{"location":"admin/config.html#databases","text":"databases : jdp : name : JGI Data Portal organization : Joint Genome Institute endpoint : globus-jdp kbase : name : KBase Workspace Service (KSS) organization : KBase endpoint : globus-kbase TODO: Alll the things","title":"databases"},{"location":"admin/docker.html","text":"Deploying DTS via Docker You can use the Dockerfile and dts.yaml files in this directory to build your Docker image. TODO: maybe say more? Deploying to NERSC's Spin Environment DTS is hosted in NERSC's Spin environment under Rancher 2 . It runs in the Production environment under the kbase organization. You can read about Spin in NERSC's documentation, and Rancher 2 here . The documentation isn't great, but fortunately there's not a lot to know--most of the materials you'll need are right here in this directory. Deploying DTS to Spin involves updating and pushing a new Docker image with any code changes and documentation updates editing the dts Spin deployment via NERSC's Rancher 2 console Each of these steps are fairly simple. Before you perform an update, take some time to familiarize yourself with the Rancher 2 console and the dts production deployment. The most important details are: The service and its supporting executables and configuration data are supplied by its Docker image The DTS data directory (used for keeping track of ongoing tasks and for generating transfer manifests) resides on the NERSC Community File System (CFS) under /global/cfs/cdirs/kbase/dts/ . This volume is visible to the service as /data . Let's walk through the process of updating and redeploying the DTS in Spin. 1. Update and Push a New Docker Image to Spin From within a clone of the DTS git repo , make sure the repo is up to date by typing git pull in the main branch. Then, sitting in the top-level source directory of your dts folder, execute the deploy-to-spin.sh script in the directory containing this README.md file, passing as arguments the name of a tag to identify the new Docker image the name of the NERSC user whose permissions are used for CFS the UID of the NERSC user the group used to determine the user's group permissions the GID of the above group For example, ./path/to/this/dir/deploy-to-spin.sh v1.1 johnson 52710 kbase 54643 builds a new DTS Docker image for to be run as the user johnson , with the tag v1.1 . The script pushes the Docker image to the Spin Docker registry . Make sure the tag indicates the current version of dts for clarity. After building the Docker image and tagging it, the script prompts you for the NERSC password for the user you specified. This allows it to push the image to NERSC's Docker image registry, where it can be accessed via the Rancher 2 console. 2. Edit the Deployment in Rancher 2 and Restart the Service Now log in to Rancher 2 and navigate to the dts deployment. Click on the dts pod to view its status and information Click on the three dots near the right side of the screen and select Edit to update its configuration. If needed, navigate to the Volumes section and edit the CFS directory for the volume mounted at /data . Usually, this is set to /global/cfs/cdirs/kbase/dts/ , so you don't need to edit this unless you want to place your mapping data store file in a different directory. Edit the Docker image for the deployment, changing the tag after the colon to match the tag of the Docker image pushed by deploy-to-spin.sh above. Make sure that the Scaling/Upgrade Policy is set to Rolling: stop old pods, then start new . This prevents a new pod from trying to acquire locks on the mapping data stores before the old one has released it. Click Save to restart the deployment with this new information. That's it! You've now updated the service with new features and bugfixes.","title":"Deploying DTS via Docker"},{"location":"admin/docker.html#deploying-dts-via-docker","text":"You can use the Dockerfile and dts.yaml files in this directory to build your Docker image. TODO: maybe say more?","title":"Deploying DTS via Docker"},{"location":"admin/docker.html#deploying-to-nerscs-spin-environment","text":"DTS is hosted in NERSC's Spin environment under Rancher 2 . It runs in the Production environment under the kbase organization. You can read about Spin in NERSC's documentation, and Rancher 2 here . The documentation isn't great, but fortunately there's not a lot to know--most of the materials you'll need are right here in this directory. Deploying DTS to Spin involves updating and pushing a new Docker image with any code changes and documentation updates editing the dts Spin deployment via NERSC's Rancher 2 console Each of these steps are fairly simple. Before you perform an update, take some time to familiarize yourself with the Rancher 2 console and the dts production deployment. The most important details are: The service and its supporting executables and configuration data are supplied by its Docker image The DTS data directory (used for keeping track of ongoing tasks and for generating transfer manifests) resides on the NERSC Community File System (CFS) under /global/cfs/cdirs/kbase/dts/ . This volume is visible to the service as /data . Let's walk through the process of updating and redeploying the DTS in Spin.","title":"Deploying to NERSC's Spin Environment"},{"location":"admin/docker.html#1-update-and-push-a-new-docker-image-to-spin","text":"From within a clone of the DTS git repo , make sure the repo is up to date by typing git pull in the main branch. Then, sitting in the top-level source directory of your dts folder, execute the deploy-to-spin.sh script in the directory containing this README.md file, passing as arguments the name of a tag to identify the new Docker image the name of the NERSC user whose permissions are used for CFS the UID of the NERSC user the group used to determine the user's group permissions the GID of the above group For example, ./path/to/this/dir/deploy-to-spin.sh v1.1 johnson 52710 kbase 54643 builds a new DTS Docker image for to be run as the user johnson , with the tag v1.1 . The script pushes the Docker image to the Spin Docker registry . Make sure the tag indicates the current version of dts for clarity. After building the Docker image and tagging it, the script prompts you for the NERSC password for the user you specified. This allows it to push the image to NERSC's Docker image registry, where it can be accessed via the Rancher 2 console.","title":"1. Update and Push a New Docker Image to Spin"},{"location":"admin/docker.html#2-edit-the-deployment-in-rancher-2-and-restart-the-service","text":"Now log in to Rancher 2 and navigate to the dts deployment. Click on the dts pod to view its status and information Click on the three dots near the right side of the screen and select Edit to update its configuration. If needed, navigate to the Volumes section and edit the CFS directory for the volume mounted at /data . Usually, this is set to /global/cfs/cdirs/kbase/dts/ , so you don't need to edit this unless you want to place your mapping data store file in a different directory. Edit the Docker image for the deployment, changing the tag after the colon to match the tag of the Docker image pushed by deploy-to-spin.sh above. Make sure that the Scaling/Upgrade Policy is set to Rolling: stop old pods, then start new . This prevents a new pod from trying to acquire locks on the mapping data stores before the old one has released it. Click Save to restart the deployment with this new information. That's it! You've now updated the service with new features and bugfixes.","title":"2. Edit the Deployment in Rancher 2 and Restart the Service"},{"location":"admin/globus.html","text":"Granting DTS Access to a Globus Endpoint The Data Transfer Service relies heavily on Globus for performing file transfers between different databases. Here we describe how to configure DTS to work with a Globus endpoint. 1. Obtain an Application/Service Credential for DTS 2. Create a Guest Collection on the Globus Endpoint 3. Grant DTS read/write access to the Guest Collection References Globus Docs: How To Use Application Credentials or Service Accounts to Automate Data Transfer","title":"Granting DTS Access to a Globus Endpoint"},{"location":"admin/globus.html#granting-dts-access-to-a-globus-endpoint","text":"The Data Transfer Service relies heavily on Globus for performing file transfers between different databases. Here we describe how to configure DTS to work with a Globus endpoint.","title":"Granting DTS Access to a  Globus Endpoint"},{"location":"admin/globus.html#1-obtain-an-applicationservice-credential-for-dts","text":"","title":"1. Obtain an Application/Service Credential for DTS"},{"location":"admin/globus.html#2-create-a-guest-collection-on-the-globus-endpoint","text":"","title":"2. Create a Guest Collection on the Globus Endpoint"},{"location":"admin/globus.html#3-grant-dts-readwrite-access-to-the-guest-collection","text":"","title":"3. Grant DTS read/write access to the Guest Collection"},{"location":"admin/globus.html#references","text":"Globus Docs: How To Use Application Credentials or Service Accounts to Automate Data Transfer","title":"References"},{"location":"admin/installation.html","text":"Installing DTS Locally Here we describe how to build, test, and install the Data Transfer Service in a local environment. Building and Testing DTS is written in Go , so you'll need a working Go compiler to build, test, and run it locally. If you have a Go compiler, you can clone this repository and build it from the top-level directory: go build Running Unit Tests DTS comes with several unit tests that demonstrate its capabilities, and you can run these tests as you would any other Go project: go test ./... You can add a -v flag to see output from the tests. Because DTS is primarily an orchestrator of network resources, its unit tests must be able to connect to and utilize these resources. Accordingly, you must set the following environment variables to make sure DTS can do what it needs to do: DTS_KBASE_DEV_TOKEN : a KBase development token (available to KBase developers used to connect to the KBase Auth Server, which provides a context for authenticating and authorizing DTS for its basic operations DTS_KBASE_TEST_ORCID : an ORCID identifier that can be used to run DTS's unit test. This identifier must match a registered ORCID ID associated with a KBase user account . DTS_KBASE_TEST_USER : the KBase user associated with the ORCID specified by DTS_KBASE_TEST_ORCID . DTS_GLOBUS_CLIENT_ID : a client ID registered using the Globus Developers web interface. This ID must be registered specifically for an instance of DTS. DTS_GLOBUS_CLIENT_SECRET : a client secret associated with the client ID specified by DTS_GLOBUS_CLIENT_ID DTS_GLOBUS_TEST_ENDPOINT : a Globus endpoint used to test DTS's transfer capabilities DTS_JDP_SECRET : a string containing a shared secret that allows the DTS to authenticate with the JGI Data Portal Installation The only remaining step is to copy the dts executable from your source directory to wherever you want it to reside. This executable is statically linked against all libraries, so it's completely portable.","title":"Installing DTS Locally"},{"location":"admin/installation.html#installing-dts-locally","text":"Here we describe how to build, test, and install the Data Transfer Service in a local environment.","title":"Installing DTS Locally"},{"location":"admin/installation.html#building-and-testing","text":"DTS is written in Go , so you'll need a working Go compiler to build, test, and run it locally. If you have a Go compiler, you can clone this repository and build it from the top-level directory: go build","title":"Building and Testing"},{"location":"admin/installation.html#running-unit-tests","text":"DTS comes with several unit tests that demonstrate its capabilities, and you can run these tests as you would any other Go project: go test ./... You can add a -v flag to see output from the tests. Because DTS is primarily an orchestrator of network resources, its unit tests must be able to connect to and utilize these resources. Accordingly, you must set the following environment variables to make sure DTS can do what it needs to do: DTS_KBASE_DEV_TOKEN : a KBase development token (available to KBase developers used to connect to the KBase Auth Server, which provides a context for authenticating and authorizing DTS for its basic operations DTS_KBASE_TEST_ORCID : an ORCID identifier that can be used to run DTS's unit test. This identifier must match a registered ORCID ID associated with a KBase user account . DTS_KBASE_TEST_USER : the KBase user associated with the ORCID specified by DTS_KBASE_TEST_ORCID . DTS_GLOBUS_CLIENT_ID : a client ID registered using the Globus Developers web interface. This ID must be registered specifically for an instance of DTS. DTS_GLOBUS_CLIENT_SECRET : a client secret associated with the client ID specified by DTS_GLOBUS_CLIENT_ID DTS_GLOBUS_TEST_ENDPOINT : a Globus endpoint used to test DTS's transfer capabilities DTS_JDP_SECRET : a string containing a shared secret that allows the DTS to authenticate with the JGI Data Portal","title":"Running Unit Tests"},{"location":"admin/installation.html#installation","text":"The only remaining step is to copy the dts executable from your source directory to wherever you want it to reside. This executable is statically linked against all libraries, so it's completely portable.","title":"Installation"},{"location":"developer/index.html","text":"DTS Developer Guide This guide explains the internal workings of the Data Transfer Service (DTS). Code Organization The following packages implement the features in the Data Transfer Service. auth : handles the authorization of the DTS using KBase's authentication/authorization server config : handles the parsing of the DTS YAML configuration file , placing the data into read-only global variables for use by other packages credit : defines metadata types used by the Credit Engine to establish the provenance of transferred data databases : defines database types that implement the integration of DTS with database providers endpoints : defines endpoint types for file transfer providers used by DTS, such as Globus frictionless : defines data structures that describe data for individual files and packages containing multiple files services : defines types that implement the REST endpoints provided by the DTS tasks : implements the \"heart\" of the DTS, which creates and manages transfer tasks through their entire lifecycle","title":"Overview"},{"location":"developer/index.html#dts-developer-guide","text":"This guide explains the internal workings of the Data Transfer Service (DTS).","title":"DTS Developer Guide"},{"location":"developer/index.html#code-organization","text":"The following packages implement the features in the Data Transfer Service. auth : handles the authorization of the DTS using KBase's authentication/authorization server config : handles the parsing of the DTS YAML configuration file , placing the data into read-only global variables for use by other packages credit : defines metadata types used by the Credit Engine to establish the provenance of transferred data databases : defines database types that implement the integration of DTS with database providers endpoints : defines endpoint types for file transfer providers used by DTS, such as Globus frictionless : defines data structures that describe data for individual files and packages containing multiple files services : defines types that implement the REST endpoints provided by the DTS tasks : implements the \"heart\" of the DTS, which creates and manages transfer tasks through their entire lifecycle","title":"Code Organization"},{"location":"developer/auth.html","text":"The auth Package TODO: stuff goes here.","title":"The `auth` Package"},{"location":"developer/auth.html#the-auth-package","text":"TODO: stuff goes here.","title":"The auth Package"},{"location":"developer/config.html","text":"The config Package TODO: stuff goes here.","title":"config package"},{"location":"developer/config.html#the-config-package","text":"TODO: stuff goes here.","title":"The config Package"},{"location":"developer/credit.html","text":"The credit Package TODO: stuff goes here.","title":"credit package"},{"location":"developer/credit.html#the-credit-package","text":"TODO: stuff goes here.","title":"The credit Package"},{"location":"developer/databases.html","text":"The databases Package TODO: stuff goes here.","title":"databases package"},{"location":"developer/databases.html#the-databases-package","text":"TODO: stuff goes here.","title":"The databases Package"},{"location":"developer/endpoints.html","text":"The endpoints Package TODO: stuff goes here.","title":"endpoints package"},{"location":"developer/endpoints.html#the-endpoints-package","text":"TODO: stuff goes here.","title":"The endpoints Package"},{"location":"developer/frictionless.html","text":"The frictionless Package TODO: stuff goes here.","title":"frictionless package"},{"location":"developer/frictionless.html#the-frictionless-package","text":"TODO: stuff goes here.","title":"The frictionless Package"},{"location":"developer/services.html","text":"The services Package TODO: stuff goes here.","title":"services package"},{"location":"developer/services.html#the-services-package","text":"TODO: stuff goes here.","title":"The services Package"},{"location":"developer/tasks.html","text":"The tasks Package TODO: stuff goes here.","title":"tasks package"},{"location":"developer/tasks.html#the-tasks-package","text":"TODO: stuff goes here.","title":"The tasks Package"}]}